% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gbm-package.r
\docType{package}
\name{gbm-package}
\alias{gbm-package}
\title{Generalized Boosted Regression Models}
\description{
This package implements extensions to Freund and Schapire's AdaBoost
algorithm and J. Friedman's gradient boosting machine. Includes regression
methods for least squares, absolute loss, logistic, Poisson, Cox
proportional hazards partial likelihood, t-distribution,
AdaBoost exponential loss, Learning to Rank, and Huberized hinge loss.
}
\details{
Further information is available in the following vignettes: \tabular{ll}{
\code{gbm} \tab Generalized Boosted Models: A guide to the gbm package
(source, pdf)\cr}
}
\references{
Y. Freund and R.E. Schapire (1997) \dQuote{A decision-theoretic
generalization of on-line learning and an application to boosting,}
\emph{Journal of Computer and System Sciences,} 55(1):119-139.

G. Ridgeway (1999). \dQuote{The state of boosting,} \emph{Computing Science
and Statistics} 31:172-181.

J.H. Friedman, T. Hastie, R. Tibshirani (2000). \dQuote{Additive Logistic
Regression: a Statistical View of Boosting,} \emph{Annals of Statistics}
28(2):337-374.

J.H. Friedman (2001). \dQuote{Greedy Function Approximation: A Gradient
Boosting Machine,} \emph{Annals of Statistics} 29(5):1189-1232.

J.H. Friedman (2002). \dQuote{Stochastic Gradient Boosting,}
\emph{Computational Statistics and Data Analysis} 38(4):367-378.

The \href{http://www-stat.stanford.edu/~jhf/R-MART.html}{MART} website.
}
\author{
James Hickey, Greg Ridgeway \email{gregridgeway@gmail.com} with contributions by
Daniel Edwards, Brian Kriegler, Stefan Schroedl and Harry Southworth.
}
\keyword{package}
